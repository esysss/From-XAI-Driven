{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637292db-8bf7-4fca-82f1-9ec5513c11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from variant_stats import get_variants_stats\n",
    "from pm4py.util import ml_utils\n",
    "import importlib.util\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.visualization.heuristics_net import visualizer as hn_visualizer\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60518782-1bc1-43e1-8fcc-2d7c3229d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_sequence_alignment_metric(path1, path2):\n",
    "    def node_similarity(node1, node2):\n",
    "        try:\n",
    "            if node1['feature_value'] == node2['feature_value']:\n",
    "                return 1  # High similarity score for exact matches in feature_value\n",
    "            elif node1['feature_abbrv'] == node2['feature_abbrv']:\n",
    "                return 0.5  # Partial similarity score for matching feature_abbrv\n",
    "            else:\n",
    "                return 0  # No similarity\n",
    "        except:\n",
    "            return 0\n",
    "    len1, len2 = len(path1), len(path2)\n",
    "    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]\n",
    "\n",
    "    for i in range(len1 + 1):\n",
    "        dp[i][0] = i * -0.1  # Penalty for adding nodes\n",
    "    for j in range(len2 + 1):\n",
    "        dp[0][j] = j * -0.1  # Penalty for deleting nodes\n",
    "\n",
    "    for i in range(1, len1 + 1):\n",
    "        for j in range(1, len2 + 1):\n",
    "            match_score = dp[i-1][j-1] + node_similarity(path1[i-1], path2[j-1])\n",
    "            delete_score = dp[i-1][j] - 0.1  # Penalty for deletion\n",
    "            insert_score = dp[i][j-1] - 0.1  # Penalty for insertion\n",
    "            dp[i][j] = max(match_score, delete_score, insert_score)\n",
    "\n",
    "    raw_score = dp[-1][-1]\n",
    "    \n",
    "    # Calculate maximum and minimum possible scores\n",
    "    max_score = min(len1, len2) * 1  # Assuming 1 is the maximum similarity per node\n",
    "    min_score = -(len1 + len2) * 0.1  # Penalty for complete mismatch\n",
    "    \n",
    "    # Normalize the score to a [0, 1] range\n",
    "    normalized_score = (raw_score - min_score) / (max_score - min_score)\n",
    "    \n",
    "    return raw_score, normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9878337-ceb5-40c3-a773-f1dd1608a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [03:01<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_pickle('decision_paths/subset_optimized_simple_size_0.2_fitnessweights_p0.34_f0.33_c0.33_weightmodel_weight_positive_simplified.pickle')\n",
    "\n",
    "dists = []\n",
    "for i in tqdm(range(len(df2))):\n",
    "    data1 = df2['rule_to_simplified_rules'].iloc[i]\n",
    "    for path1 in data1:\n",
    "        temp_dist = []\n",
    "        for j in range(len(df2)):\n",
    "            data2 = df2['rule_to_simplified_rules'].iloc[j]\n",
    "            for path2 in data2:\n",
    "                raw_score, normalized_score = calculate_similarity_sequence_alignment_metric(path1, path2)\n",
    "                temp_dist.append(normalized_score)\n",
    "        dists.append(temp_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d998ebea-7edf-4567-9d5c-f491ea87e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_dist = np.array(dists)\n",
    "np.fill_diagonal(np_dist, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b68476ca-3d00-4f1e-a0d6-dd9abfa0b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: 2138\n"
     ]
    }
   ],
   "source": [
    "zero_count = np.count_nonzero(np_dist == 0)\n",
    "print(f\"Number of zeros: {zero_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8abb6d7-a968-4d10-8ce4-d5de54059722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2138, 2138)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19cc832d-4c14-4984-bf84-df4faf981ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "np_dist[np_dist>threshold] = 1\n",
    "np_dist[np_dist<1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fbb0d34-e7b4-4d47-8fd1-38f5ef13cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(np_dist)\n",
    "for u, v, d in G.edges(data=True):\n",
    "    d['weight'] = np_dist[u, v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca1d6638-953e-4b9c-8f1e-dcc005463190",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'community' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommunity\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommunity_louvain\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[43mcommunity\u001b[49m\u001b[38;5;241m.\u001b[39mbest_partition(G, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'community' is not defined"
     ]
    }
   ],
   "source": [
    "import community as community_louvain\n",
    "\n",
    "partition = community.best_partition(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780a8f06-e1ef-4626-b13c-00ecc8a317af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57decff-8bfa-4d72-a9a5-cc65d5a35f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
